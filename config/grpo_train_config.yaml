training_args:
  # training args
  max_steps: 50
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  learning_rate: 5.0e-7 
  lr_scheduler_type: cosine
  warmup_ratio: 0.03
  bf16: true
  tf32: true
  output_dir: /scratch/gpfs/zs7353/LLMNegotiation/Llama-3.2-3B-Instruct_negotiation
  save_strategy: "steps"
  save_steps: 25

  # grpo specific args
  beta: 0.001 
  max_prompt_length: 256
  max_completion_length: 1024
  num_generations: 8

other_args:
  # model arguments
  model_name_or_path: /scratch/gpfs/zs7353/Llama-3.2-3B-Instruct
  model_revision: main
  torch_dtype: bfloat16

  # dataset arguments
  dataset_name_or_path: /home/zs7353/LLMNegotiation/negotiation_data/rl_dataset.jsonl

  # lora arguments
  r: 8 
  alpha: 16               
  dropout: 0.1