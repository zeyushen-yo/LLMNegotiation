training_args:
  # training args
  max_steps: 10
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  learning_rate: 5.0e-7 
  lr_scheduler_type: cosine
  warmup_ratio: 0.03

  # grpo specific args
  beta: 0.001 
  max_prompt_length: 256
  max_completion_length: 1024
  num_generations: 8
  use_vllm: true
  vllm_gpu_memory_utilization: 0.5

other_args:
  # logging arguments
  logging_strategy: steps
  logging_steps: 2
  report_to: 
  - tensorboard
  save_strategy: "steps"
  save_steps: 25
  seed: 42

  # hf hub
  push_to_hub: true
  hub_strategy: every_save

  # model arguments
  model_name_or_path: /scratch/gpfs/zs7353/DeepSeek-R1-Distill-Llama-8B
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
  bf16: true
  tf32: true
  output_dir: /scratch/gpfs/zs7353/LLMNegotiation/DeepSeek-R1-Distill-Llama-8B_negotiation

  # dataset arguments
  dataset_name: /home/zs7353/LLMNegotiation/negotiation_data/rl_dataset.jsonl

  # lora arguments
  r: 8 
  alpha: 16               
  dropout: 0.1